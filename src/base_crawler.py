"""
BaseCrawler - çˆ¬è™«åŸºç±»
æä¾›å¼‚æ­¥ç‰ˆæœ¬çš„å…¬å…±é€»è¾‘
"""

from abc import ABC, abstractmethod
from src.utils import setup_logger

logger = setup_logger("creeper")


class BaseCrawler(ABC):
    """çˆ¬è™«åŸºç±»,åŒ…å«å…¬å…±é€»è¾‘"""

    def __init__(self, args):
        """
        åˆå§‹åŒ–å…¬å…±å±æ€§

        Args:
            args: å‘½ä»¤è¡Œå‚æ•°
        """
        self.args = args
        self.stats = {
            'total': 0,
            'success': 0,
            'skipped': 0,
            'failed': 0
        }
        self.failed_items = []

        # å­ç±»è´Ÿè´£åˆå§‹åŒ–çš„æ¨¡å—
        self.parser = None
        self.dedup = None
        self.fetcher = None
        self.storage = None
        self.cookie_manager = None

    @abstractmethod
    def run(self):
        """è¿è¡Œçˆ¬è™« - å­ç±»å®ç°"""
        pass

    @abstractmethod
    def _process_url(self, item):
        """å¤„ç†å•ä¸ª URL - å­ç±»å®ç°"""
        pass

    def _display_stats(self):
        """æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "=" * 60)
        print("ğŸ“Š çˆ¬å–ç»Ÿè®¡")
        print("=" * 60)
        print(f"æ€»è®¡:   {self.stats['total']} ä¸ª URL")
        print(f"æˆåŠŸ:   {self.stats['success']} ä¸ª âœ“")
        print(f"è·³è¿‡:   {self.stats['skipped']} ä¸ª âŠ˜")
        print(f"å¤±è´¥:   {self.stats['failed']} ä¸ª âœ—")

        if self.stats['total'] > 0:
            success_rate = (self.stats['success'] / self.stats['total']) * 100
            print(f"æˆåŠŸç‡: {success_rate:.1f}%")

        print("=" * 60)

        # æ˜¾ç¤ºè¾“å‡ºç›®å½•
        if self.storage:
            storage_stats = self.storage.get_stats()
            print(f"\nè¾“å‡ºç›®å½•: {storage_stats['output_dir']}")
            print(f"ç”Ÿæˆæ–‡ä»¶: {storage_stats['total_files']} ä¸ª")
