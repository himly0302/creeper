#!/usr/bin/env python3
"""
Creeper - ç½‘é¡µçˆ¬è™«å·¥å…·
å°† Markdown æ–‡ä»¶ä¸­çš„ URL æ‰¹é‡çˆ¬å–å¹¶ä¿å­˜ä¸ºç»“æ„åŒ–çš„æœ¬åœ° Markdown æ–‡æ¡£
"""

import sys
import argparse
from pathlib import Path
from tqdm import tqdm

from src.parser import MarkdownParser
from src.dedup import DedupManager
from src.fetcher import WebFetcher
from src.storage import StorageManager
from src.config import config
from src.utils import setup_logger

logger = setup_logger("creeper")


class Creeper:
    """Creeper ä¸»ç±»"""

    def __init__(self, args):
        """
        åˆå§‹åŒ– Creeper

        Args:
            args: å‘½ä»¤è¡Œå‚æ•°
        """
        self.args = args
        self.stats = {
            'total': 0,
            'success': 0,
            'skipped': 0,
            'failed': 0
        }
        self.failed_items = []

        # åˆå§‹åŒ–å„ä¸ªæ¨¡å—
        self.parser = None
        self.dedup = DedupManager()
        self.fetcher = WebFetcher(use_playwright=not args.no_playwright)
        self.storage = StorageManager(args.output)

    def run(self):
        """è¿è¡Œçˆ¬è™«"""
        try:
            logger.info("=" * 60)
            logger.info(f"Creeper v0.1.0 - å¼€å§‹è¿è¡Œ")
            logger.info("=" * 60)

            # 1. è§£æ Markdown æ–‡ä»¶
            logger.info(f"æ­£åœ¨è§£ææ–‡ä»¶: {self.args.input_file}")
            self.parser = MarkdownParser(self.args.input_file)
            items = self.parser.parse()

            if not items:
                logger.warning("æœªæ‰¾åˆ°ä»»ä½• URL,ç¨‹åºé€€å‡º")
                return

            self.stats['total'] = len(items)
            logger.info(f"å…±æ‰¾åˆ° {self.stats['total']} ä¸ª URL")

            # æ˜¾ç¤ºæ–‡æ¡£ç»“æ„(å¦‚æœæ˜¯è°ƒè¯•æ¨¡å¼)
            if config.DEBUG:
                self.parser.display_structure()

            # 2. æµ‹è¯• Redis è¿æ¥
            if not self.dedup.test_connection():
                logger.warning("Redis è¿æ¥å¤±è´¥,å°†è·³è¿‡å»é‡æ£€æŸ¥")

            # 3. å¤„ç†æ¯ä¸ª URL
            logger.info("å¼€å§‹çˆ¬å–ç½‘é¡µ...")
            with tqdm(total=len(items), desc="çˆ¬å–è¿›åº¦", unit="url") as pbar:
                for item in items:
                    self._process_url(item, pbar)

            # 4. ä¿å­˜å¤±è´¥çš„ URL
            if self.failed_items:
                self.storage.save_failed_urls(self.failed_items)

            # 5. æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            self._display_stats()

            logger.info("=" * 60)
            logger.info("çˆ¬å–ä»»åŠ¡å®Œæˆ!")
            logger.info("=" * 60)

        except KeyboardInterrupt:
            logger.warning("\nç”¨æˆ·ä¸­æ–­ç¨‹åº")
            self._display_stats()
            sys.exit(1)
        except Exception as e:
            logger.error(f"ç¨‹åºå¼‚å¸¸: {e}", exc_info=config.DEBUG)
            sys.exit(1)
        finally:
            # æ¸…ç†èµ„æº
            self.fetcher.close()
            self.dedup.close()

    def _process_url(self, item, pbar):
        """
        å¤„ç†å•ä¸ª URL

        Args:
            item: URLItem å¯¹è±¡
            pbar: è¿›åº¦æ¡å¯¹è±¡
        """
        url = item.url
        pbar.set_description(f"å¤„ç†: {url[:50]}...")

        try:
            # å»é‡æ£€æŸ¥
            if not self.args.force and self.dedup.is_crawled(url):
                logger.info(f"âŠ˜ è·³è¿‡(å·²çˆ¬å–): {url}")
                self.stats['skipped'] += 1
                pbar.update(1)
                return

            # çˆ¬å–ç½‘é¡µ
            page = self.fetcher.fetch(url)

            if not page.success:
                logger.error(f"âœ— çˆ¬å–å¤±è´¥: {url} - {page.error}")
                self.stats['failed'] += 1
                self.failed_items.append((item, page.error or "æœªçŸ¥é”™è¯¯"))
                pbar.update(1)
                return

            # ä¿å­˜æ–‡ä»¶
            file_path = self.storage.save(item, page)

            if file_path:
                # æ ‡è®°ä¸ºå·²çˆ¬å–
                self.dedup.mark_crawled(url)
                self.stats['success'] += 1
                logger.info(f"âœ“ æˆåŠŸ: {url}")
            else:
                self.stats['failed'] += 1
                self.failed_items.append((item, "ä¿å­˜æ–‡ä»¶å¤±è´¥"))
                logger.error(f"âœ— ä¿å­˜å¤±è´¥: {url}")

        except Exception as e:
            logger.error(f"âœ— å¤„ç†å¼‚å¸¸: {url} - {e}")
            self.stats['failed'] += 1
            self.failed_items.append((item, str(e)))
        finally:
            pbar.update(1)

    def _display_stats(self):
        """æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "=" * 60)
        print("ğŸ“Š çˆ¬å–ç»Ÿè®¡")
        print("=" * 60)
        print(f"æ€»è®¡:   {self.stats['total']} ä¸ª URL")
        print(f"æˆåŠŸ:   {self.stats['success']} ä¸ª âœ“")
        print(f"è·³è¿‡:   {self.stats['skipped']} ä¸ª âŠ˜")
        print(f"å¤±è´¥:   {self.stats['failed']} ä¸ª âœ—")

        if self.stats['total'] > 0:
            success_rate = (self.stats['success'] / self.stats['total']) * 100
            print(f"æˆåŠŸç‡: {success_rate:.1f}%")

        print("=" * 60)

        # æ˜¾ç¤ºè¾“å‡ºç›®å½•
        storage_stats = self.storage.get_stats()
        print(f"\nè¾“å‡ºç›®å½•: {storage_stats['output_dir']}")
        print(f"ç”Ÿæˆæ–‡ä»¶: {storage_stats['total_files']} ä¸ª")


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description='Creeper - ç½‘é¡µçˆ¬è™«å·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  %(prog)s input.md                    # åŸºæœ¬ä½¿ç”¨
  %(prog)s input.md -o ./output        # æŒ‡å®šè¾“å‡ºç›®å½•
  %(prog)s input.md --debug            # å¼€å¯è°ƒè¯•æ¨¡å¼
  %(prog)s input.md --force            # å¼ºåˆ¶é‡æ–°çˆ¬å–
  %(prog)s input.md --no-playwright    # ç¦ç”¨ Playwright

æ›´å¤šä¿¡æ¯: https://github.com/your-repo/creeper
        """
    )

    parser.add_argument(
        'input_file',
        type=str,
        help='Markdown è¾“å…¥æ–‡ä»¶è·¯å¾„'
    )

    parser.add_argument(
        '-o', '--output',
        type=str,
        default=config.OUTPUT_DIR,
        help=f'è¾“å‡ºç›®å½• (é»˜è®¤: {config.OUTPUT_DIR})'
    )

    parser.add_argument(
        '-c', '--concurrency',
        type=int,
        default=config.CONCURRENCY,
        help=f'å¹¶å‘æ•° (é»˜è®¤: {config.CONCURRENCY}, MVP ç‰ˆæœ¬æš‚ä¸æ”¯æŒ)'
    )

    parser.add_argument(
        '--force',
        action='store_true',
        help='å¼ºåˆ¶é‡æ–°çˆ¬å–(è·³è¿‡å»é‡æ£€æŸ¥)'
    )

    parser.add_argument(
        '--debug',
        action='store_true',
        help='å¼€å¯è°ƒè¯•æ¨¡å¼'
    )

    parser.add_argument(
        '--no-playwright',
        action='store_true',
        help='ç¦ç”¨ Playwright(ä»…ä½¿ç”¨é™æ€çˆ¬å–)'
    )

    parser.add_argument(
        '-v', '--version',
        action='version',
        version='Creeper 0.1.0 (MVP)'
    )

    return parser.parse_args()


def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‚æ•°
    args = parse_args()

    # è®¾ç½®è°ƒè¯•æ¨¡å¼
    if args.debug:
        config.DEBUG = True
        config.LOG_LEVEL = 'DEBUG'
        # é‡æ–°è®¾ç½® logger
        import logging
        logging.getLogger("creeper").setLevel(logging.DEBUG)

    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not Path(args.input_file).exists():
        logger.error(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input_file}")
        sys.exit(1)

    # è¿è¡Œçˆ¬è™«
    creeper = Creeper(args)
    creeper.run()


if __name__ == '__main__':
    main()
