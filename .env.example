# ==================== Redis 配置 ====================
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=1
REDIS_PASSWORD=
# Redis Key 前缀
REDIS_KEY_PREFIX=creeper:

# ==================== 爬虫配置 ====================
# 并发数(建议 5-10,避免触发反爬虫)
CONCURRENCY=5

# 请求超时(秒)
REQUEST_TIMEOUT=30

# 请求间隔(秒)
MIN_DELAY=1
MAX_DELAY=3

# 最大重试次数
MAX_RETRIES=1

# 重试间隔(秒,指数退避)
RETRY_BASE_DELAY=2

# ==================== 浏览器配置 ====================
# Playwright 浏览器类型: chromium, firefox, webkit
BROWSER_TYPE=chromium

# 浏览器 headless 模式
BROWSER_HEADLESS=true

# 页面加载超时(毫秒)
PAGE_TIMEOUT=30000

# ==================== User-Agent 池 ====================
# 多个 User-Agent 用逗号分隔,爬虫会随机选择
USER_AGENTS=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36,Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36,Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36

# ==================== 内容提取配置 ====================
# 是否包含评论
INCLUDE_COMMENTS=false

# 是否包含表格
INCLUDE_TABLES=true

# 是否包含图片
INCLUDE_IMAGES=true

# 最小文本长度(字符数,过短的内容视为提取失败)
MIN_TEXT_LENGTH=100

# ==================== 输出配置 ====================
# 默认输出目录
OUTPUT_DIR=./output

# 文件名最大长度
MAX_FILENAME_LENGTH=100

# 是否保存失败的 URL 到文件
SAVE_FAILED_URLS=true

# ==================== 图片下载配置 ====================
# 是否下载图片到本地
DOWNLOAD_IMAGES=false

# 最大图片大小限制(MB)
MAX_IMAGE_SIZE_MB=10

# 图片下载超时时间(秒)
IMAGE_DOWNLOAD_TIMEOUT=30

# 支持的图片格式(逗号分隔)
SUPPORTED_IMAGE_FORMATS=.jpg,.jpeg,.png,.gif,.webp,.svg

# 强制使用 requests 库下载的域名列表（逗号分隔）
# 这些域名的图片会使用 requests 库而不是 aiohttp 库下载
# 用于解决某些域名（如 BBC）的连接兼容性问题
# 支持子域名匹配，配置 example.com 会影响 sub.example.com
#
# 常见问题域名示例：
# FORCE_REQUESTS_DOMAINS=bbci.co.uk,bbc.com,example-problematic.com
#
# 如果不配置此项，系统会自动使用默认的 BBC 域名配置
# 留空表示只使用默认配置：FORCE_REQUESTS_DOMAINS=
FORCE_REQUESTS_DOMAINS=

# ==================== Cookie 管理配置 ====================
# Cookie 存储方式: file 或 redis
# - file: 使用 JSON/Pickle 文件存储(适合单次使用)
# - redis: 使用 Redis 存储(适合跨会话复用,需要 Redis)
COOKIE_STORAGE=redis

# Cookie 在 Redis 中的过期天数
COOKIE_EXPIRE_DAYS=7

# Cookie 在 Redis 中的 Key 前缀
COOKIE_REDIS_KEY_PREFIX=creeper:cookie:

# ==================== Cookie 保存策略配置 ====================
# 是否只保存目标域名相关的 Cookie（减少第三方 Cookie）
SAVE_TARGET_DOMAIN_COOKIES_ONLY=false

# 是否保存第三方 Cookie（广告、跟踪等）
SAVE_THIRD_PARTY_COOKIES=true

# 是否输出详细的 Cookie 保存日志（减少日志噪音）
VERBOSE_COOKIE_LOGGING=false

# 交互式登录超时时间(秒)
INTERACTIVE_LOGIN_TIMEOUT=300

# ==================== 翻译配置 ====================
# 是否启用翻译功能
ENABLE_TRANSLATION=false

# DeepSeek API 配置 (用于翻译功能)
# 获取 API Key: https://platform.deepseek.com/
DEEPSEEK_API_KEY=sk-your-translation-api-key-here
DEEPSEEK_BASE_URL=https://api.deepseek.com
DEEPSEEK_MODEL=deepseek-chat

# 翻译范围(选择性翻译)
TRANSLATE_TITLE=true              # 翻译标题
TRANSLATE_DESCRIPTION=true        # 翻译摘要
TRANSLATE_CONTENT=true            # 翻译正文
TRANSLATE_METADATA=false          # 翻译元数据(作者等)

# ==================== LLM 模型能力自动探测 ====================
# 是否启用模型能力自动探测（默认: true）
# 启用后，首次调用 LLM 时会自动询问模型的 token 限制
ENABLE_MODEL_AUTO_DETECTION=true

# 模型探测超时时间（秒，默认: 10）
MODEL_DETECTION_TIMEOUT=10

# ==================== 特殊网站处理配置 ====================
# 需要宽松处理的网站列表（域名匹配，逗号分隔）
# 这些网站在遇到403等错误时会尝试继续处理，内容质量检查也更宽松
PERMISSIVE_DOMAINS=wikipedia.org,wikimedia.org,github.com,stackoverflow.com,docs.python.org

# 特殊网站的HTTP状态码宽容配置
# 格式：域名:状态码列表，用分号分隔不同域名的配置
# 例如：wikipedia.org:403;wikimedia.org:403;github.com:403,404
PERMISSIVE_STATUS_CODES=wikipedia.org:403;wikimedia.org:403;github.com:403,404

# 特殊网站的内容质量配置
# 格式：域名:最小长度:中文最小字符:英文最小字符:错误指示词跳过
# 错误指示词跳过：为空表示不跳过任何指示词，多个用逗号分隔
# 例如：wikipedia.org:100:20:50:404 表示维基百科至少100字符，中文20或英文50字符，跳过404错误指示词
PERMISSIVE_CONTENT_RULES=wikipedia.org:100:20:50:404;wikimedia.org:100:20:50:404;github.com:50:10:25:404;stackoverflow.com:100:15:30:

# ==================== 调试配置 ====================
# 调试模式(true/false)
DEBUG=false

# 日志级别: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# 日志文件路径
LOG_FILE=creeper.log
